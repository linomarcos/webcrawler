"""
Search query infrastructure for indexed web pages.

The method searcher.buildIndex 'transposes the matrix' of urls-vs-words in the database generated by the crawler class. This is the key toward accellerating queries.
"""
import pymongo
import crawler, wordcount

class searcher(wordcount.wordcount):
	"""Main usage of the class is via 2 methods:
	(1) buildIndex() = builds 'transpose matrix' for querying words against urls and locations,
	(2) simpleQuery(str) = for a string 'str' of whitespace-separated tokens, returns a dictionary of all urls containing those tokens plus information about their locations.

	The collection of indexed webpages is accessible via self.indexdb, and is initialized in the parent class. 
	"""
	def __init__(self, dbPrefix='test'):
		# call base class constructor
		wordcount.wordcount.__init__(self, dbPrefix)
		wordsName = '_'.join([dbPrefix,'words'])
		print "word index: database collection '"+wordsName+"'"
		# _mdbcon = connection to MongoDB in base class
		self._wordscol = self._mdbcon[wordsName]
		self.wordsdb = self._wordscol[wordsName]

	def __del__(self):
		# ignore the destructor of the parent class, since the only thing that needs 
		# to be done is kill the connection of the database.
		self._mdbcon.disconnect()

	def buildIndex(self):
		"""Builds a reduced map of words-to-urls for accelerating queries."""
		print self.__module__, ': building word index'
		for jsobj in self.indexdb.find():
			url = jsobj['url']
			words = jsobj['words']
			for j in range(len(words)):
				if words[j] in self.blackList:
					continue
				rec = {'word':words[j], 'url':url, 'pos':j}
				self.wordsdb.insert(rec)

	def selectURLs(self, word, Range={}):
		"""Helper routine for query methods. Queries the database wordsdb for all urls's where the word is present.
		Params: Range = dictionary of pairs url:1 representing the _subset_ of urls from which to query. Ignored if empty.
		Returns: dictionary of pairs url:1 representing all urls returned by the query.
		"""
		match = {}
		if len(Range.items()) == 0:
			for jsobj in self.wordsdb.find({'word':word}) :
				match[jsobj['url']] = 1
		else:
			for jsobj in self.wordsdb.find({'word':word}) :
				if Range.has_key(jsobj['url']):
					match[jsobj['url']] = 1
		return match

	def simpleQuery(self, string):
		"""Tokenizes the query string and finds documents containing all tokens.
		Returns: a pair (tokens, results), where:
		- tokens = list of tokenized search terms.
		- results = dictionary of structured data:
		{ url: { token[0]:[..positions..], token[1]:[..positions..],..},...}
		That is, each record is indexed by an url. Its value is a dictionary whose key-value pairs are each a token and a list of positions (integers) of that token in the document.
		"""
		range = {}
		results = {}
		tokens = crawler.tokenize(string) 
		for word in tokens:
			range = self.selectURLs(word, range)
			# check whether selectURLs returned no results
			if len(range) == 0:
				return (tokens, results) 
		for url in range:
			results[url] = {}
			for word in tokens:
				results[url][word] = []
				cursor = self.wordsdb.find({'url':url, 'word': word})
				for rec in cursor:
					results[url][word].append(rec['pos'])
		
		return (tokens, results)

# include unit tests out of laziness...
import unittest

class testAll(unittest.TestCase):
	"""Unit tests for the searcher class."""
	eta = 0.14
	query_str = 'something special'

	def setUp(self):
		self.C = searcher()
		self.C.count(testAll.eta)

	def tearDown(self):
		# pass
		self.C.wordsdb.drop()

	# def test_build(self):
	# 	pass
	# 	self.C.buildIndex()
	# 	cursor = self.C.wordsdb.find()
	# 	print '%25s%60s%10s' % ('WORD','URL', 'POS')
	# 	for rec in cursor[0:20] :
	# 		print '%25s%60s%10s' % (rec['word'], rec['url'], rec['pos'])
	
	def test_simpleQuery(self):
		self.C.buildIndex()
		print "searching for '"+testAll.query_str+"'"
		(tokens, results) = self.C.simpleQuery(testAll.query_str)
		for r in results:
			print r

if __name__ == '__main__':
	unittest.main()
